---
layout: post
title:  "SQuAD: 100,000+ Questions for Machine Comprehension of Text(2016)"
subtitle:   "부제"
categories: AI
tags: papers
comments: true

---

인공지능을 공부하고 논문을 읽다 보면, 분명히 많은 개선의 여지가 남아있는 분야임에도 모델을 학습시키고 평가하기 위한 데이터셋이 양이 충분하지 않거나, 오염도가 심해서 연구 자체가 어려운 경우가 정말 많다. 예를 들어, 인공지능이 처음 보는 악보를 보고도 높은 수준의 피아노 연주를 해내기 위해서는 최소 수만 개 이상의 높은 수준의 피아노 연주 데이터가 필요할 것이다. 또는, 인공지능이 분자생물학 실험을 위한 최적의 조건을 설계해주기 위해서는 적절한 변인통제 속에서 실험 조건과 그에 따른 실험 결과 데이터를 수만 번 이상 쌓아야 한다. 당연하게도 이러한 데이터를 높은 퀄리티로 많이 마련한다는 것은 굉장한 자본과 노동이 필요한 작업이다. 그래서, 누군가가 이러한 데이터셋을 만들어내기 전까지는, AI 피아니스트가 탁월한 연주를 해내거나, AI가 최고의 실험 조건을 설계해주는 것을 기대하기 어렵다.

이처럼 AI 연구에 있어서 적절한 데이터셋은 모델이 목적에 맞게 잘 학습되게 해줄 뿐더러, 학계에서 모델의 성능을 비교할 수 있는 객관적인 기준을 마련해주기 때문에 여러모로 중요하다. 사실상 한 데이터셋의 등장이 하나의 연구분야를 열었다고 해도 과언이 아닌 경우도 적지 않다. 아마, 이 논문에서 제시한 데이터셋도 이와 비슷한 경우 중 하나가 아닐까 하고 생각한다. SQuAD(Sanford Question Answering Dataset)는 현재까지도 QA(question answering) 분야에서 가장 자주 사용되는 데이터셋 중 하나로, 인공지능 모델이 주어진 텍스트의 정보를 바탕으로 질문에 답하는 과정을 훈련 및 평가할 수 있는 데이터셋이다.

![img Alt]({{ site.baseurl }}/assets/img/squad_example.PNG)

물론, QA라는 분야와 관련 데이터셋 자체는 제법 오래 전부터 있었다. 하지만, 기존의 데이터셋은 퀄리티가 높으면(즉, 인력이 투입되면) 양이 적고, 양이 많으면(컴퓨터가 수집했으면) 오염도가 심하다는 문제가 있었다. SQuAD는 이러한 trade-off 관계에서 두 마리의 토끼를 모두 잡은 데이터셋으로, Wikipedia에서 추출한 텍스트를 기반으로 한 (발표 당시) 10만 개 이상의 question-answer pairs를 제공한다. 또한, SQuAD는 주어진 몇 개의 보기에서 정답을 선택하는 것이 아니라, 제공된 paragraph에서 answer span을 찾는 식으로 task를 설계했기 때문에, QA 모델에게 이전보다 더욱 높은 수준의 과제 수행 능력을 요구한다.

그렇다면 연구진은 어떻게 이처럼 양이 많으면서도 퀄리티가 높은 데이터셋을 만들어낼 수 있었을까? 우선, Wikipedia는 모든 자료가 신뢰할만큼 논리적, 그리고 형식적으로 잘 구성된 데이터베이스가 아니다. 그래서 먼저 '좋은 글이라고 믿을 만한' 조회수 top 10000의 문서들을 긁어모았다. 그리고 각각의 문서들에 대해 적절한 전처리를 진행한 뒤, 크라우드소싱을 사용해 문서로부터 적절한 질문과 답안을 생성하였다. 이후, 문답 작성 참여자들 간의 적절한 교차검증을 통해 데이터셋의 신뢰도를 높였다. 또한, 데이터셋에서 요구하는 독해 및 추론 능력의 종류나 질문의 내용이 한쪽으로 치우치지 않음을 검증하였다.

SQuAD는 현재까지도 QA 성능을 평가하기 위한 훌륭한 기준으로 사용되고 있지만, 분명한 한계점 또한 갖고 있는 데이터셋이다. 예를 들어, SQuAD는 답안을 주어진 paragraph 속에서 span으로 찾도록 하기 때문에, 답안이 항상 정확히 같은 형태로 paragraph 속에 들어있어야 한다. 이는 QA 모델이 푸는 문답의 복잡도나 다양성을 크게 제한할 수 있다. 가령, 실제 인간의 경우를 생각해본다면, 인간은 주어진 paragraph에서 주어진 질문의 답이 implicit하게 주어지더라도 여러 단계의 논리적 추론을 연결해 문제를 해결할 수 있다. 하지만 SQuAD는 이러한 상황을 배제하며, 이러한 데이터셋의 제약은 SQuAD를 기반으로 학습한 QA 모델이 implicit하게 주어진 논리적 추론 관계를 학습하기 어렵다는 제약으로 이어질 수 있다.

이처럼 데이터셋은 모델을 훈련시키는 중요한 토대가 되기 때문에, 인공지능을 학습시킬 때에는 늘 학습에 사용하는 데이터셋을 정확히 이해해야 한다. 그리고, 데이터셋이 내포하는 한계와 모델 성능의 한계점을 연결해서 개선 방향을 고민하는 것이 좋다.



논문 링크 및 이미지 출처: [https://arxiv.org/abs/1606.05250]({{ site.baseurl }}https://arxiv.org/abs/1606.05250)